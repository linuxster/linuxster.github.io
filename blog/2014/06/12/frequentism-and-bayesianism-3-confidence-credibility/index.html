<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Frequentism and Bayesianism III: Confidence, Credibility, and why Frequentism and Science do not Mix</title>
  <meta name="author" content="Jake Vanderplas">

  <link href="/atom.xml" type="application/atom+xml" rel="alternate"
        title="Pythonic Perambulations Atom Feed" />


  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link href="/favicon.png" rel="icon">
  <link href="/theme/css/main.css" media="screen, projection"
        rel="stylesheet" type="text/css">
  <script src="/theme/js/modernizr-2.0.js"></script>
  <script src="/theme/js/ender.js"></script>
  <script src="/theme/js/octopress.js" type="text/javascript"></script>

  <link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
  <link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
</head>

<body>
  <header role="banner"><hgroup>
  <h1><a href="/">Pythonic Perambulations</a></h1>
    <h2>Musings and ramblings through the world of Python and beyond</h2>
</hgroup></header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-atom">Atom</a></li>
</ul>


<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>

<ul class="main-navigation">
    <li><a href="/archives.html">Archives</a></li>
    <li><a href="http://www.astro.washington.edu/users/vanderplas">Home Page</a></li>
</ul></nav>
  <div id="main">
    <div id="content">
<div>
  <article class="hentry" role="article">
<header>
      <h1 class="entry-title">Frequentism and Bayesianism III: Confidence, Credibility, and why Frequentism and Science do not Mix</h1>
      <p class="meta"><time datetime="2014-06-12T12:00:00" pubdate>Jun 12, 2014</time></p>
</header>

  <div class="entry-content"><p>
<div class="text_cell_render border-box-sizing rendered_html">


<p>In Douglas Adams' classic <em>Hitchhiker's Guide to the Galaxy</em>, hyper-intelligent pan-dimensional beings build a computer named <em>Deep Thought</em> in order to calculate &quot;the Answer to the Ultimate Question of Life, the Universe, and Everything&quot;. After seven and a half million years spinning its hyper-dimensional gears, before an excited crowd, Deep Thought finally outputs the answer:</p>
<p><strong>42</strong></p>
<p>The disappointed technicians, who trained a lifetime for this moment, are stupefied. They probe Deep Though for more information, and after some back-and-forth, the computer responds: &quot;once you do know what the question actually is, you'll know what the answer means.&quot;</p>
<p>An answer does you no good if you don't know the question.</p>
<p>I find this story be an apt metaphor for statistics as sometimes used in the scientific literature. When trying to estimate the value of an unknown parameter, the frequentist approach generally relies on a <strong>confidence interval</strong> (CI), while the Bayesian approach relies on a <strong>credible region</strong> (CR). While these concepts sound and look very similar, their subtle difference can be extremely important, as they answer essentially different questions.</p>
<p>Like the poor souls hoping for enlightenment in Douglas Adams' universe, scientists often turn the crank of frequentism hoping for useful answers, but in the process overlook the fact that in science, <strong>frequentism is generally answering the wrong question.</strong> This is far from simple philosophical navel-gazing: as I'll show, it can have real consequences for the conclusions we draw from observed data.</p>


</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Confidence-vs.-Credibility">Confidence vs. Credibility<a class="anchor-link" href="#Confidence-vs.-Credibility">&#182;</a></h2>
</div>

<div class="text_cell_render border-box-sizing rendered_html">
<p>In <a href="http://jakevdp.github.io/blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/">part I</a> of this series, we discussed the basic philosophical difference between frequentism and Bayesianism: frequentists consider probability a measure of <strong>the frequency of (perhaps hypothetical) repeated events</strong>; Bayesians consider probability as a measure of <strong>the degree of certainty about values</strong>. As a result of this, speaking broadly, frequentists consider <strong>model parameters to be fixed and data to be random</strong>, while Bayesians consider <strong>model parameters to be random and data to be fixed</strong>.</p>
<p>These philosophies fundamenally affect the way that each approach seeks bounds on the value of a model parameter. Because the differences here are subtle, I'll go right into a simple example to illustrate the difference between a frequentist confidence interval and a Bayesian credible region.</p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Example-1:-The-Mean-of-a-Gaussian">Example 1: The Mean of a Gaussian<a class="anchor-link" href="#Example-1:-The-Mean-of-a-Gaussian">&#182;</a></h2>
</div>

<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's start by again examining an extremely simple problem; this is the same problem we saw in <a href="http://jakevdp.github.io/blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/">part I</a> of this series: finding the mean of a Gaussian distribution. Previously we simply looked at the (frequentist) maximum likelihood and (Bayesian) maximum a posteriori estimates; here we'll extend this and look at confidence intervals and credibile regions.</p>
<p>Here is the problem: imagine you're observing a star that you assume has a constant brightness. Simplistically, we can think of this brightness as the number of photons reaching our telescope in one second. Any given measurement of this number will be subject to measurement errors: the source of those errors is not important right now, but let's assume the observations <span class="math">\(x_i\)</span> are drawn from a normal distribution about the true brightness value with a known standard deviation <span class="math">\(\sigma_x\)</span>.</p>
<p>Given a series of measurements, what are the 95% (i.e. <span class="math">\(2\sigma\)</span>) limits that we would place on the brightness of the star?</p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="1.-The-Frequentist-Approach">1. The Frequentist Approach<a class="anchor-link" href="#1.-The-Frequentist-Approach">&#182;</a></h3>
</div>

<div class="text_cell_render border-box-sizing rendered_html">
<p>The frequentist approach to this problem is well-known, and is as follows:</p>
<p>For any set of <span class="math">\(N\)</span> values <span class="math">\(D = \{x_i\}_{i=1}^N\)</span>, an unbiased estimate of the mean <span class="math">\(\mu\)</span> of the distribution is given by</p>
<p><span class="math">\[
\bar{x} = \frac{1}{N}\sum_{i=1}^N x_i
\]</span></p>
<p>The <strong>sampling distribution</strong> describes the observed frequency of the estimate of the mean; by the central limit theorem we can show that the sampling distribution is normal; i.e.</p>
<p><span class="math">\[
f(\bar{x}~||~\mu) \propto \exp\left[\frac{-(\bar{x} - \mu)^2}{2\sigma_\mu^2}\right]
\]</span></p>
<p>where we've used the <strong>standard error of the mean</strong>,</p>
<p><span class="math">\[
\sigma_\mu = \sigma_x / \sqrt{N}
\]</span></p>
<p>The central limit theorem tells us that this is a reasonable approximation for any generating distribution if <span class="math">\(N\)</span> is large; if our generating distribution happens to be Gaussian, it also holds for <span class="math">\(N\)</span> as small as 2.</p>
<p>Let's quickly check this empirically, by looking at <span class="math">\(10^6\)</span> samples of the mean of 5 numbers:</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[20]:
</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">N</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">Nsamp</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">**</span> <span class="mi">6</span>
<span class="n">sigma_x</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma_x</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">Nsamp</span><span class="p">,</span> <span class="n">N</span><span class="p">))</span>
<span class="n">mu_samp</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">sig_samp</span> <span class="o">=</span> <span class="n">sigma_x</span> <span class="o">*</span> <span class="n">N</span> <span class="o">**</span> <span class="o">-</span><span class="mf">0.5</span>

<span class="k">print</span><span class="p">(</span><span class="s">&quot;{0:.3f} should equal {1:.3f}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">mu_samp</span><span class="p">),</span> <span class="n">sig_samp</span><span class="p">))</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_stream output_stdout">
<pre>
0.894 should equal 0.894

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>It checks out: the standard deviation of the observed means is equal to <span class="math">\(\sigma_x N^{-1/2}\)</span>, as expected.</p>
<p>From this normal sampling distribution, we can quickly write the 95% confidence interval by recalling that two standard deviations is roughly equivalent to 95% of the area under the curve. So our confidence interval is</p>
<p><span class="math">\[
CI_{\mu} =  \left(\bar{x} - 2\sigma_\mu,~\bar{x} + 2\sigma_\mu\right)
\]</span></p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's try this with a quick example: say we have three observations with an error (i.e. <span class="math">\(\sigma_x\)</span>) of 10. What is our 95% confidence interval on the mean?</p>
<p>We'll generate our observations assuming a true value of 100:</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[21]:
</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="n">true_B</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">sigma_x</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">D</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">true_B</span><span class="p">,</span> <span class="n">sigma_x</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">D</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_stream output_stdout">
<pre>
[ 116.24345364   93.88243586   94.71828248]

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next let's create a function which will compute the confidence interval:</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[22]:
</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="kn">from</span> <span class="nn">scipy.special</span> <span class="kn">import</span> <span class="n">erfinv</span>

<span class="k">def</span> <span class="nf">freq_CI_mu</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">frac</span><span class="o">=</span><span class="mf">0.95</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute the confidence interval on the mean&quot;&quot;&quot;</span>
    <span class="c"># we&#39;ll compute Nsigma from the desired percentage</span>
    <span class="n">Nsigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">erfinv</span><span class="p">(</span><span class="n">frac</span><span class="p">)</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">D</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">sigma_mu</span> <span class="o">=</span> <span class="n">sigma</span> <span class="o">*</span> <span class="n">D</span><span class="o">.</span><span class="n">size</span> <span class="o">**</span> <span class="o">-</span><span class="mf">0.5</span>
    <span class="k">return</span> <span class="n">mu</span> <span class="o">-</span> <span class="n">Nsigma</span> <span class="o">*</span> <span class="n">sigma_mu</span><span class="p">,</span> <span class="n">mu</span> <span class="o">+</span> <span class="n">Nsigma</span> <span class="o">*</span> <span class="n">sigma_mu</span>

<span class="k">print</span><span class="p">(</span><span class="s">&quot;95% Confidence Interval: [{0:.0f}, {1:.0f}]&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">freq_CI_mu</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="mi">10</span><span class="p">)))</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_stream output_stdout">
<pre>
95% Confidence Interval: [90, 113]

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>Note here that we've assumed <span class="math">\(\sigma_x\)</span> is a known quantity; this could also be estimated from the data along with <span class="math">\(\mu\)</span>, but here we kept things simple for sake of example.</p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="2.-The-Bayesian-Approach">2. The Bayesian Approach<a class="anchor-link" href="#2.-The-Bayesian-Approach">&#182;</a></h3>
</div>

<div class="text_cell_render border-box-sizing rendered_html">
<p>For the Bayesian approach, we start with Bayes' theorem:</p>
<p><span class="math">\[
P(\mu~|~D) = \frac{P(D~|~\mu)P(\mu)}{P(D)}
\]</span></p>
<p>We'll use a flat prior on <span class="math">\(\mu\)</span> (i.e. <span class="math">\(P(\mu) \propto 1\)</span> over the region of interest) and use the likelihood</p>
<p><span class="math">\[
P(D~|~\mu) = \prod_{i=1}^N \frac{1}{\sqrt{2\pi\sigma_x^2}}\exp\left[\frac{(\mu - x_i)^2}{2\sigma_x^2}\right]
\]</span></p>
<p>Computing this product and manipulating the terms, it's straightforward to show that this gives</p>
<p><span class="math">\[
P(\mu~|~D) \propto \exp\left[\frac{-(\mu - \bar{x})^2}{2\sigma_\mu^2}\right]
\]</span></p>
<p>which is recognizable as a normal distribution with mean <span class="math">\(\bar{x}\)</span> and standard deviation <span class="math">\(\sigma_\mu\)</span>. That is, <strong>the Bayesian posterior on <span class="math">\(\mu\)</span> in this case is exactly equal to the frequentist sampling distribution for <span class="math">\(\mu\)</span></strong>.</p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>From this posterior, we can compute the Bayesian credible region, which is the shortest interval that contains 95% of the probability. Here, it looks exactly like the frequentist confidence interval:</p>
<p><span class="math">\[
CR_{\mu} =  \left(\bar{x} - 2\sigma_\mu,~\bar{x} + 2\sigma_\mu\right)
\]</span></p>
<p>For completeness, we'll also create a function to compute the Bayesian credible region:</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[23]:
</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="k">def</span> <span class="nf">bayes_CR_mu</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">frac</span><span class="o">=</span><span class="mf">0.95</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute the credible region on the mean&quot;&quot;&quot;</span>
    <span class="n">Nsigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">erfinv</span><span class="p">(</span><span class="n">frac</span><span class="p">)</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">D</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">sigma_mu</span> <span class="o">=</span> <span class="n">sigma</span> <span class="o">*</span> <span class="n">D</span><span class="o">.</span><span class="n">size</span> <span class="o">**</span> <span class="o">-</span><span class="mf">0.5</span>
    <span class="k">return</span> <span class="n">mu</span> <span class="o">-</span> <span class="n">Nsigma</span> <span class="o">*</span> <span class="n">sigma_mu</span><span class="p">,</span> <span class="n">mu</span> <span class="o">+</span> <span class="n">Nsigma</span> <span class="o">*</span> <span class="n">sigma_mu</span>

<span class="k">print</span><span class="p">(</span><span class="s">&quot;95% Credible Region: [{0:.0f}, {1:.0f}]&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">bayes_CR_mu</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="mi">10</span><span class="p">)))</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_stream output_stdout">
<pre>
95% Credible Region: [90, 113]

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="So-What's-the-Difference?">So What's the Difference?<a class="anchor-link" href="#So-What's-the-Difference?">&#182;</a></h3>
</div>

<div class="text_cell_render border-box-sizing rendered_html">
<p>The above derivation is one reason why the frequentist confidence interval and the Bayesian credible region are so often confused. In many simple problems, they correspond exactly. But we must be clear that <strong>even though the two are numerically equivalent, their interpretation is very different</strong>.</p>
<p>Recall that in Bayesianism, the probability distributions reflect our degree of belief. So when we computed the credible region above, it's equivalent to saying</p>
<blockquote>
<p>&quot;Given our observed data, there is a 95% probability that the true value of <span class="math">\(\mu\)</span> falls within <span class="math">\(CR_\mu\)</span>&quot; - Bayesians</p>
</blockquote>
<p>In frequentism, on the other hand, <span class="math">\(\mu\)</span> is considered a fixed value and the data (and all quantities derived from the data, including the bounds of the confidence interval) are random variables. So the frequentist confidence interval is equivalent to saying</p>
<blockquote>
<p>&quot;There is a 95% probability that when I compute <span class="math">\(CI_\mu\)</span> from data of this sort, the true mean will fall within <span class="math">\(CI_\mu\)</span>.&quot; - Frequentists</p>
</blockquote>
<p>Note the difference: the Bayesian solution is a statement of probability about the parameter value given fixed bounds. The frequentist solution is a probability about the bounds given a fixed parameter value. This follows directly from the philosophical definitions of probability that the two approaches are based on.</p>
<p>The difference is subtle, but, as I'll discuss below, it has drastic consequences. First, let's further clarify these notions by running some simulations to confirm the interpretation.</p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Confirming-the-Bayesian-Credible-Region">Confirming the Bayesian Credible Region<a class="anchor-link" href="#Confirming-the-Bayesian-Credible-Region">&#182;</a></h4>
</div>

<div class="text_cell_render border-box-sizing rendered_html">
<p>To confirm what the Bayesian credible region is claiming, we must do the following:</p>
<ol style="list-style-type: decimal">
<li>sample random <span class="math">\(\mu\)</span> values from the prior</li>
<li>sample random sets of points given each <span class="math">\(\mu\)</span></li>
<li>select the sets of points which match our observed data</li>
<li>ask what fraction of these <span class="math">\(\mu\)</span> values are within the credible region we've constructed.</li>
</ol>
<p>In code, that looks like this:</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[24]:
</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="c"># first define some quantities that we need </span>
<span class="n">Nsamples</span> <span class="o">=</span> <span class="mf">2E7</span>
<span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">D</span><span class="p">)</span>
<span class="n">sigma_x</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c"># if someone changes N, this could easily cause a memory error</span>
<span class="k">if</span> <span class="n">N</span> <span class="o">*</span> <span class="n">Nsamples</span> <span class="o">&gt;</span> <span class="mf">1E8</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;Are you sure you want this many samples?&quot;</span><span class="p">)</span>
    
<span class="c"># eps tells us how close to D we need to be to consider</span>
<span class="c"># it a matching sample. The value encodes the tradeoff</span>
<span class="c"># between bias and variance of our simulation</span>
<span class="n">eps</span> <span class="o">=</span> <span class="mf">0.5</span>

<span class="c"># Generate some mean values from the (flat) prior in a reasonable range</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">mu</span> <span class="o">=</span> <span class="mi">80</span> <span class="o">+</span> <span class="mi">40</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">Nsamples</span><span class="p">)</span>

<span class="c"># Generate data for each of these mean values</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma_x</span><span class="p">,</span> <span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">Nsamples</span><span class="p">))</span><span class="o">.</span><span class="n">T</span>

<span class="c"># find data which matches matches our &quot;observed&quot; data</span>
<span class="n">x</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">D</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
<span class="n">i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">D</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">eps</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">&quot;number of suitable samples: {0}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="o">.</span><span class="n">sum</span><span class="p">()))</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_stream output_stdout">
<pre>
number of suitable samples: 528

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[25]:
</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="c"># Now we ask how many of these mu values fall in our credible region</span>
<span class="n">mu_good</span> <span class="o">=</span> <span class="n">mu</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<span class="n">CR</span> <span class="o">=</span> <span class="n">bayes_CR_mu</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">within_CR</span> <span class="o">=</span> <span class="p">(</span><span class="n">CR</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">mu_good</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">mu_good</span> <span class="o">&lt;</span> <span class="n">CR</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="k">print</span> <span class="s">&quot;Fraction of means in Credible Region: {0:.3f}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">within_CR</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">*</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">within_CR</span><span class="o">.</span><span class="n">size</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_stream output_stdout">
<pre>
Fraction of means in Credible Region: 0.949

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>We see that, as predicted, roughly 95% of <span class="math">\(\mu\)</span> values with data matching ours lie in the Credible Region.</p>
<p>The important thing to note here is which of the variables is random, and which are fixed. In the Bayesian approach, we compute <strong>a single credible region from our observed data</strong>, and we consider it in terms of <strong>multiple random draws of <span class="math">\(\mu\)</span></strong>.</p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Confirming-the-frequentist-Confidence-Interval">Confirming the frequentist Confidence Interval<a class="anchor-link" href="#Confirming-the-frequentist-Confidence-Interval">&#182;</a></h4>
</div>

<div class="text_cell_render border-box-sizing rendered_html">
<p>Confirmation of the interpretation of the frequentist confidence interval is a bit less involved. We do the following:</p>
<ol style="list-style-type: decimal">
<li>draw sets of values from the distribution defined by the single true value of <span class="math">\(\mu\)</span>.</li>
<li>for each set of values, compute a new confidence interval.</li>
<li>determine what fraction of these confidence intervals contain <span class="math">\(\mu\)</span>.</li>
</ol>
<p>In code, it looks like this:</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[26]:
</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="c"># define some quantities we need</span>
<span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">D</span><span class="p">)</span>
<span class="n">Nsamples</span> <span class="o">=</span> <span class="mf">1E4</span>
<span class="n">mu</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">sigma_x</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c"># Draw datasets from the true distribution</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma_x</span><span class="p">,</span> <span class="p">(</span><span class="n">Nsamples</span><span class="p">,</span> <span class="n">N</span><span class="p">))</span>

<span class="c"># Compute a confidence interval from each dataset</span>
<span class="n">CIs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">freq_CI_mu</span><span class="p">(</span><span class="n">Di</span><span class="p">,</span> <span class="n">sigma_x</span><span class="p">)</span> <span class="k">for</span> <span class="n">Di</span> <span class="ow">in</span> <span class="n">x</span><span class="p">])</span>

<span class="c"># find which confidence intervals contain the mean</span>
<span class="n">contains_mu</span> <span class="o">=</span> <span class="p">(</span><span class="n">CIs</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">mu</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">mu</span> <span class="o">&lt;</span> <span class="n">CIs</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="k">print</span> <span class="s">&quot;Fraction of Confidence Intervals containing the mean: {0:.3f}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">contains_mu</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">*</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">contains_mu</span><span class="o">.</span><span class="n">size</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_stream output_stdout">
<pre>
Fraction of Confidence Intervals containing the mean: 0.951

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>We see that, as predicted, 95% of the confidence intervals contain the true value of <span class="math">\(\mu\)</span>.</p>
<p>Again, the important thing to note here is which of the variables is random. We use <strong>a single value of <span class="math">\(\mu\)</span></strong>, and consider it in relation to <strong>multiple confidence intervals constructed from multiple random data samples</strong>.</p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Discussion">Discussion<a class="anchor-link" href="#Discussion">&#182;</a></h3>
</div>

<div class="text_cell_render border-box-sizing rendered_html">
<p>We should remind ourselves again of the difference between the two types of constraints:</p>
<ul>
<li>The Bayesian approach fixes the credible region, and guarantees 95% of possible values of <span class="math">\(\mu\)</span> will fall within it.</li>
<li>The frequentist approach fixes the parameter, and guarantees that 95% of possible confidence intervals will contain it.</li>
</ul>
<p>Comparing the frequentist confirmation and the Bayesian confirmation above, we see that the distinctions which stem from the very definition of probability mentioned above:</p>
<ul>
<li>Bayesianism treats parameters (e.g. <span class="math">\(\mu\)</span>) as random variables, while frequentism treats parameters as fixed.</li>
<li>Bayesianism treats observed data (e.g. <span class="math">\(D\)</span>) as fixed, while frequentism treats data as random variables.</li>
<li>Bayesianism treats its parameter constraints (e.g. <span class="math">\(CR_\mu\)</span>) as fixed, while frequentism treats its constraints (e.g. <span class="math">\(CI_\mu\)</span>) as random variables.</li>
</ul>
<p>In the above example, as in many simple problems, the confidence interval and the credibility region overlap exactly, so the distinction is not especially important. But scientific analysis is rarely this simple; next we'll consider an example in which the choice of approach makes a big difference.</p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Example-2:-Jaynes'-Truncated-Exponential">Example 2: Jaynes' Truncated Exponential<a class="anchor-link" href="#Example-2:-Jaynes'-Truncated-Exponential">&#182;</a></h2>
</div>

<div class="text_cell_render border-box-sizing rendered_html">
<p>For an example of a situation in which the frequentist confidence interval and the Bayesian credibility region <em>do not</em> overlap, I'm going to turn to an example given by E.T. Jaynes, a 20th century physicist who wrote extensively on statistical inference in Physics. In the fifth example of his <em>Confidence Intervals vs. Bayesian Intervals</em> (<a href="http://bayes.wustl.edu/etj/articles/confidence.pdf">pdf</a>), he considers a truncated exponential model. Here is the problem, in his words:</p>
<blockquote>
<p>A device will operate without failure for a time <span class="math">\(\theta\)</span> because of a protective chemical inhibitor injected into it; but at time <span class="math">\(\theta\)</span> the supply of the chemical is exhausted, and failures then commence, following the exponential failure law. It is not feasible to observe the depletion of this inhibitor directly; one can observe only the resulting failures. From data on actual failure times, estimate the time <span class="math">\(\theta\)</span> of guaranteed safe operation...</p>
</blockquote>
<p>Essentially, we have data <span class="math">\(D\)</span> drawn from the following model:</p>
<p><span class="math">\[
p(x~|~\theta) = \left\{
\begin{array}{lll}
\exp(\theta - x) &amp;,&amp; x &gt; \theta\\
0                &amp;,&amp; x &lt; \theta
\end{array}
\right\}
\]</span></p>
<p>where <span class="math">\(p(x~|~\theta)\)</span> gives the probability of failure at time <span class="math">\(x\)</span>, given an inhibitor which lasts for a time <span class="math">\(\theta\)</span>. Given some observed data <span class="math">\(D = \{x_i\}\)</span>, we want to estimate <span class="math">\(\theta\)</span>.</p>
<p>Let's start by plotting this model for a particular value of <span class="math">\(\theta\)</span>, so we can see what we're working with:</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[27]:
</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="o">%</span><span class="k">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="k">def</span> <span class="nf">p</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">theta</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="n">theta</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">theta</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">&#39;p(x)&#39;</span><span class="p">);</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYQAAAEPCAYAAABCyrPIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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">

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>Imagine now that we've observed some data, <span class="math">\(D = \{10, 12, 15\}\)</span>, and we want to infer the value of <span class="math">\(\theta\)</span> from this data. We'll explore four approaches to this below.</p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="1.-Common-Sense-Approach">1. Common Sense Approach<a class="anchor-link" href="#1.-Common-Sense-Approach">&#182;</a></h3>
</div>

<div class="text_cell_render border-box-sizing rendered_html">
<p>One general tip that I'd always recommend: in any problem, before computing anything, think about what you're computing and guess what a reasonable solution might be. We'll start with that here. Thinking about the problem, the hard cutoff in the probability distribution leads to one simple observation: <strong><span class="math">\(\theta\)</span> must be smaller than the smallest observed value</strong>.</p>
<p>This is immediately obvious on examination: the probability of seeing a value less than <span class="math">\(\theta\)</span> is zero. Thus, a model with <span class="math">\(\theta\)</span> greater than any observed value is impossible, assuming our model specification is correct. Our fundamental assumption in both Bayesianism and frequentism is that the model is correct, so in this case, we can immediately write our common sense condition:</p>
<p><span class="math">\[
\theta &lt; \min(D)
\]</span></p>
<p>or, in the particular case of <span class="math">\(D = \{10, 12, 15\}\)</span>,</p>
<p><span class="math">\[
\theta &lt; 10
\]</span></p>
<p>Any reasonable constraint on <span class="math">\(\theta\)</span> given this data should meet this criterion. With this in mind, let's go on to some quantitative approaches based on Frequentism and Bayesianism.</p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="2.-Frequentist-approach-#1:-Sampling-Distribution-via-the-Normal-Approximation">2. Frequentist approach #1: Sampling Distribution via the Normal Approximation<a class="anchor-link" href="#2.-Frequentist-approach-#1:-Sampling-Distribution-via-the-Normal-Approximation">&#182;</a></h3>
</div>

<div class="text_cell_render border-box-sizing rendered_html">
<p>In the frequentist paradigm, we'd like to compute a confidence interval on the value of <span class="math">\(\theta\)</span>. We can start by observing that the population mean is given by</p>
<p><span class="math">\[
\begin{array}{ll}
E(x) &amp;= \int_0^\infty xp(x)dx\\
     &amp;= \theta + 1
     \end{array}
\]</span></p>
<p>So, using the sample mean as the point estimate of <span class="math">\(E(x)\)</span>, we have an unbiased estimator for <span class="math">\(\theta\)</span> given by</p>
<p><span class="math">\[
\hat{\theta} = \frac{1}{N} \sum_{i=1}^N x_i - 1
\]</span></p>
<p>The exponential distribution has a standard deviation of 1, so in the limit of large <span class="math">\(N\)</span>, we can use the standard error of the mean (as above) to show that the sampling distribution of <span class="math">\(\hat{\theta}\)</span> will approach normal with variance <span class="math">\(\sigma^2 = 1 / N\)</span>. Given this, we can write our 95% (i.e. 2<span class="math">\(\sigma\)</span>) confidence interval as</p>
<p><span class="math">\[
CI_{\rm large~N} = \left(\hat{\theta} - 2 N^{-1/2},~\hat{\theta} + 2 N^{-1/2}\right)
\]</span></p>
<p>Let's write a function which will compute this, and evaluate it for our data:</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[28]:
</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="kn">from</span> <span class="nn">scipy.special</span> <span class="kn">import</span> <span class="n">erfinv</span>

<span class="k">def</span> <span class="nf">approx_CI</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">sig</span><span class="o">=</span><span class="mf">0.95</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Approximate truncated exponential confidence interval&quot;&quot;&quot;</span>
    <span class="c"># use erfinv to convert percentage to number of sigma</span>
    <span class="n">Nsigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">erfinv</span><span class="p">(</span><span class="n">sig</span><span class="p">)</span>
    <span class="n">D</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">D</span><span class="p">)</span>
    <span class="n">N</span> <span class="o">=</span> <span class="n">D</span><span class="o">.</span><span class="n">size</span>
    <span class="n">theta_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">D</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">theta_hat</span> <span class="o">-</span> <span class="n">Nsigma</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">N</span><span class="p">),</span>
            <span class="n">theta_hat</span> <span class="o">+</span> <span class="n">Nsigma</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">N</span><span class="p">)]</span>
</pre></div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[29]:
</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="n">D</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">15</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="s">&quot;approximate CI: ({0:.1f}, {1:.1f})&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">approx_CI</span><span class="p">(</span><span class="n">D</span><span class="p">)))</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_stream output_stdout">
<pre>
approximate CI: (10.2, 12.5)

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>We immediately see an issue. By our simple common sense argument, we've determined that it is impossible for <span class="math">\(\theta\)</span> to be greater than 10, yet the entirety of the 95% confidence interval is above this range! Perhaps this issue is due to the small sample size: the above computation is based on a large-<span class="math">\(N\)</span> approximation, and we have a relatively paltry <span class="math">\(N = 3\)</span>. Maybe this will be improved if we do the more computationally intensive exact approach. Let's try it:</p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="3.-Frequentist-approach-#2:-Exact-Sampling-Distribution">3. Frequentist approach #2: Exact Sampling Distribution<a class="anchor-link" href="#3.-Frequentist-approach-#2:-Exact-Sampling-Distribution">&#182;</a></h3>
</div>

<div class="text_cell_render border-box-sizing rendered_html">
<p>Computing the confidence interval from the exact sampling distribution takes a bit more work.</p>
<p>For small <span class="math">\(N\)</span>, the normal approximation will not apply, and we must instead compute the confidence integral from the actual sampling distribution, which is the distribution of the mean of <span class="math">\(N\)</span> variables each distributed according to <span class="math">\(p(\theta)\)</span>. The sum of random variables is distributed according to the convolution of the distributions for individual variables, so we can exploit the <a href="http://en.wikipedia.org/wiki/Convolution_theorem">convolution theorem</a> and use the method of [characteristic functions](http://en.wikipedia.org/wiki/Characteristic_function_(probability_theory) to find the following sampling distribution for the sum of <span class="math">\(N\)</span> variables distributed according to our particular <span class="math">\(p(x~|~\theta)\)</span>:</p>
<p><span class="math">\[
f(\theta~|~D) \propto
\left\{
\begin{array}{lll}
z^{N - 1}\exp(-z) &amp;,&amp; z &gt; 0\\
0 &amp;,&amp; z &lt; 0
\end{array}
\right\}
;~ z = N(\hat{\theta} + 1 - \theta)
\]</span></p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>To compute the 95% confidence interval, we can start by computing the cumulative distribution: we integrate <span class="math">\(f(\theta~|~D)\)</span> from <span class="math">\(0\)</span> to <span class="math">\(\theta\)</span>. This is relatively painless if we make use of the expression for the <a href="http://en.wikipedia.org/wiki/Incomplete_gamma_function">incomplete gamma function</a>:</p>
<p><span class="math">\[
\Gamma(a, x) = \int_x^\infty t^{a - 1}e^{-t} dt
\]</span></p>
<p>which looks strikingly similar to our <span class="math">\(f(\theta)\)</span>.</p>
<p>Using this to perform the integral, we find that the cumulative distribution is given by</p>
<p><span class="math">\[
F(\theta~|~D) = \frac{1}{\Gamma(N)}\left[ \Gamma\left(N, \max[0, N(\hat{\theta} + 1 - \theta)]\right) - \Gamma\left(N,~N(\hat{\theta} + 1)\right)\right]
\]</span></p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>A contiguous 95% confidence interval <span class="math">\((\theta_1, \theta_2)\)</span> satisfies the following equation:</p>
<p><span class="math">\[
F(\theta_2~|~D) - F(\theta_1~|~D) = 0.95
\]</span></p>
<p>There are in fact an infinite set of solutions to this; what we want is the shortest of these. We'll add the constraint that the probability density is equal at either side of the interval:</p>
<p><span class="math">\[
f(\theta_2~|~D) = f(\theta_1~|~D)
\]</span></p>
<p>(Jaynes claims that this criterion ensures the shortest possible interval, but I'm not sure how to prove that). Solving this system of two nonlinear equations will give us the desired confidence interval. Let's compute this numerically:</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[30]:
</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="kn">from</span> <span class="nn">scipy.special</span> <span class="kn">import</span> <span class="n">gammaincc</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">optimize</span>


<span class="k">def</span> <span class="nf">exact_CI</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">frac</span><span class="o">=</span><span class="mf">0.95</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Exact truncated exponential confidence interval&quot;&quot;&quot;</span>
    <span class="n">D</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">D</span><span class="p">)</span>
    <span class="n">N</span> <span class="o">=</span> <span class="n">D</span><span class="o">.</span><span class="n">size</span>
    <span class="n">theta_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">D</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>

    <span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">D</span><span class="p">):</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">theta_hat</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">theta</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">z</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="n">z</span> <span class="o">**</span> <span class="p">(</span><span class="n">N</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">N</span> <span class="o">*</span> <span class="n">z</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">F</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">D</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">gammaincc</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">N</span> <span class="o">*</span> <span class="p">(</span><span class="n">theta_hat</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">theta</span><span class="p">)))</span> <span class="o">-</span> <span class="n">gammaincc</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">N</span> <span class="o">*</span> <span class="p">(</span><span class="n">theta_hat</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">eqns</span><span class="p">(</span><span class="n">CI</span><span class="p">,</span> <span class="n">D</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Equations which should be equal to zero&quot;&quot;&quot;</span>
        <span class="n">theta1</span><span class="p">,</span> <span class="n">theta2</span> <span class="o">=</span> <span class="n">CI</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">F</span><span class="p">(</span><span class="n">theta2</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span> <span class="o">-</span> <span class="n">F</span><span class="p">(</span><span class="n">theta1</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span> <span class="o">-</span> <span class="n">frac</span><span class="p">,</span>
                <span class="n">f</span><span class="p">(</span><span class="n">theta2</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span> <span class="o">-</span> <span class="n">f</span><span class="p">(</span><span class="n">theta1</span><span class="p">,</span> <span class="n">D</span><span class="p">))</span>
    
    <span class="n">guess</span> <span class="o">=</span> <span class="n">approx_CI</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="mf">0.68</span><span class="p">)</span> <span class="c"># use 1-sigma interval as a guess</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">optimize</span><span class="o">.</span><span class="n">root</span><span class="p">(</span><span class="n">eqns</span><span class="p">,</span> <span class="n">guess</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">D</span><span class="p">,))</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">result</span><span class="o">.</span><span class="n">success</span><span class="p">:</span>
        <span class="k">print</span> <span class="s">&quot;warning: CI result did not converge!&quot;</span>
    <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">x</span>
</pre></div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>As a sanity check, let's make sure that the exact and approximate confidence intervals match for a large number of points:</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[31]:
</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">Dlarge</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="mi">500</span><span class="p">)</span>
<span class="k">print</span> <span class="s">&quot;approx: ({0:.3f}, {1:.3f})&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">approx_CI</span><span class="p">(</span><span class="n">Dlarge</span><span class="p">))</span>
<span class="k">print</span> <span class="s">&quot;exact: ({0:.3f}, {1:.3f})&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">exact_CI</span><span class="p">(</span><span class="n">Dlarge</span><span class="p">))</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_stream output_stdout">
<pre>
approx: (9.409, 9.584)
exact: (9.408, 9.584)

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>As expected, the approximate solution is very close to the exact solution for large <span class="math">\(N\)</span>, which gives us confidence that we're computing the right thing.</p>
<p>Let's return to our 3-point dataset and see the results:</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[32]:
</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="k">print</span><span class="p">(</span><span class="s">&quot;approximate CI: ({0:.1f}, {1:.1f})&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">approx_CI</span><span class="p">(</span><span class="n">D</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">&quot;exact CI:       ({0:.1f}, {1:.1f})&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">exact_CI</span><span class="p">(</span><span class="n">D</span><span class="p">)))</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_stream output_stdout">
<pre>
approximate CI: (10.2, 12.5)
exact CI:       (10.2, 12.2)

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>The exact confidence interval is slightly different than the approximate one, but still reflects the same problem: <strong>we know from common-sense reasoning that <span class="math">\(\theta\)</span> can't be greater than 10, yet the 95% confidence interval is entirely in this forbidden region</strong>! The confidence interval seems to be giving us unreliable results.</p>
<p>We'll discuss this in more depth further below, but first let's see if Bayes can do better.</p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="4.-Bayesian-Credibility-Interval">4. Bayesian Credibility Interval<a class="anchor-link" href="#4.-Bayesian-Credibility-Interval">&#182;</a></h3>
</div>

<div class="text_cell_render border-box-sizing rendered_html">
<p>For the Bayesian solution, we start by writing Bayes' rule:</p>
<p><span class="math">\[
p(\theta~|~D) = \frac{p(D~|~\theta)p(\theta)}{P(D)}
\]</span></p>
<p>Using a constant prior <span class="math">\(p(\theta)\)</span>, and with the likelihood</p>
<p><span class="math">\[
p(D~|~\theta) = \prod_{i=1}^N p(x~|~\theta)
\]</span></p>
<p>we find</p>
<p><span class="math">\[
p(\theta~|~D) \propto \left\{
\begin{array}{lll}
N\exp\left[N(\theta - \min(D))\right] &amp;,&amp; \theta &lt; \min(D)\\
0                &amp;,&amp; \theta &gt; \min(D)
\end{array}
\right\}
\]</span></p>
<p>where <span class="math">\(\min(D)\)</span> is the smallest value in the data <span class="math">\(D\)</span>, which enters because of the truncation of <span class="math">\(p(x~|~\theta)\)</span>. Because <span class="math">\(p(\theta~|~D)\)</span> increases exponentially up to the cutoff, the shortest 95% credibility interval <span class="math">\((\theta_1, \theta_2)\)</span> will be given by</p>
<p><span class="math">\[
\theta_2 = \min(D)
\]</span></p>
<p>and <span class="math">\(\theta_1\)</span> given by the solution to the equation</p>
<p><span class="math">\[
\int_{\theta_1}^{\theta_2} N\exp[N(\theta - \theta_2)]d\theta = f
\]</span></p>
<p>this can be solved analytically by evaluating the integral, which gives</p>
<p><span class="math">\[
\theta_1 = \theta_2 + \frac{\log(1 - f)}{N}
\]</span></p>
<p>Let's write a function which computes this:</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[33]:
</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="k">def</span> <span class="nf">bayes_CR</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">frac</span><span class="o">=</span><span class="mf">0.95</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Bayesian Credibility Region&quot;&quot;&quot;</span>
    <span class="n">D</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">D</span><span class="p">)</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">D</span><span class="o">.</span><span class="n">size</span><span class="p">)</span>
    <span class="n">theta2</span> <span class="o">=</span> <span class="n">D</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
    <span class="n">theta1</span> <span class="o">=</span> <span class="n">theta2</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">frac</span><span class="p">)</span> <span class="o">/</span> <span class="n">N</span>
    <span class="k">return</span> <span class="n">theta1</span><span class="p">,</span> <span class="n">theta2</span>
</pre></div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now that we have this Bayesian method, we can compare the results of the four methods:</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[34]:
</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="k">print</span><span class="p">(</span><span class="s">&quot;common sense:         theta &lt; {0:.1f}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">D</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">&quot;frequentism (approx): 95% CI = ({0:.1f}, {1:.1f})&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">approx_CI</span><span class="p">(</span><span class="n">D</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">&quot;frequentism (exact):  95% CI = ({0:.1f}, {1:.1f})&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">exact_CI</span><span class="p">(</span><span class="n">D</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">&quot;Bayesian:             95% CR = ({0:.1f}, {1:.1f})&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">bayes_CR</span><span class="p">(</span><span class="n">D</span><span class="p">)))</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_stream output_stdout">
<pre>
common sense:         theta &lt; 10.0
frequentism (approx): 95% CI = (10.2, 12.5)
frequentism (exact):  95% CI = (10.2, 12.2)
Bayesian:             95% CR = (9.0, 10.0)

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>What we find is that the Bayesian result agrees with our common sense, while the frequentist approach does not. The problem is that <strong>frequentism is answering the wrong question</strong>. I'll discuss this more below, but first let's do some simulations to make sure the CI and CR in this case are correct.</p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Numerical-Confirmation">Numerical Confirmation<a class="anchor-link" href="#Numerical-Confirmation">&#182;</a></h3>
</div>

<div class="text_cell_render border-box-sizing rendered_html">
<p>To try to quell any doubts about the math here, I want to repeat the exercise we did above and show that <em>the confidence interval derived above is, in fact, correct</em>. We'll use the same approach as before, assuming a &quot;true&quot; value for <span class="math">\(\theta\)</span> and sampling data from the associated distribution:</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[35]:
</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">expon</span>

<span class="n">Nsamples</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">theta</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">expon</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span><span class="o">.</span><span class="n">rvs</span><span class="p">((</span><span class="n">Nsamples</span><span class="p">,</span> <span class="n">N</span><span class="p">))</span>
<span class="n">CIs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">exact_CI</span><span class="p">(</span><span class="n">Di</span><span class="p">)</span> <span class="k">for</span> <span class="n">Di</span> <span class="ow">in</span> <span class="n">data</span><span class="p">])</span>

<span class="c"># find which confidence intervals contain the mean</span>
<span class="n">contains_theta</span> <span class="o">=</span> <span class="p">(</span><span class="n">CIs</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">theta</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">theta</span> <span class="o">&lt;</span> <span class="n">CIs</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="k">print</span> <span class="s">&quot;Fraction of Confidence Intervals containing theta: {0:.3f}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">contains_theta</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">*</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">contains_theta</span><span class="o">.</span><span class="n">size</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_stream output_stdout">
<pre>
Fraction of Confidence Intervals containing theta: 0.953

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>As is promised by frequentism, 95% of the computed confidence intervals contain the true value. The procedure we used to compute the confidence intervals is, in fact, correct: our data just happened to be among the 5% where the method breaks down. But here's the thing: <strong>we know from the data themselves that we are in the 5% where the CI fails</strong>. The fact that the standard frequentist confidence interval ignores this common-sense information should give you pause about blind reliance on the confidence interval for any nontrivial problem.</p>
<p>For good measure, let's check that the Bayesian credible region also passes its test:</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[38]:
</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">N</span> <span class="o">=</span> <span class="mf">1E7</span>
<span class="n">eps</span> <span class="o">=</span> <span class="mf">0.1</span>

<span class="n">theta</span> <span class="o">=</span> <span class="mi">9</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">(</span><span class="n">theta</span> <span class="o">+</span> <span class="n">expon</span><span class="p">()</span><span class="o">.</span><span class="n">rvs</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="n">N</span><span class="p">)))</span><span class="o">.</span><span class="n">T</span>
<span class="n">data</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">D</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
<span class="n">i_good</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">data</span> <span class="o">-</span> <span class="n">D</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">eps</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">&quot;Number of good samples: {0}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i_good</span><span class="o">.</span><span class="n">sum</span><span class="p">()))</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_stream output_stdout">
<pre>
Number of good samples: 65

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[39]:
</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="n">theta_good</span> <span class="o">=</span> <span class="n">theta</span><span class="p">[</span><span class="n">i_good</span><span class="p">]</span>
<span class="n">theta1</span><span class="p">,</span> <span class="n">theta2</span> <span class="o">=</span> <span class="n">bayes_CR</span><span class="p">(</span><span class="n">D</span><span class="p">)</span>

<span class="n">within_CR</span> <span class="o">=</span> <span class="p">(</span><span class="n">theta1</span> <span class="o">&lt;</span> <span class="n">theta_good</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">theta_good</span> <span class="o">&lt;</span> <span class="n">theta2</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">&quot;Fraction of thetas in Credible Region: {0:.3f}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">within_CR</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">*</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">within_CR</span><span class="o">.</span><span class="n">size</span><span class="p">))</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_stream output_stdout">
<pre>
Fraction of thetas in Credible Region: 0.954

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>Again, we have confirmed that, as promised, ~95% of the suitable values of <span class="math">\(\theta\)</span> fall in the credible region we computed from our single observed sample.</p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Frequentism-Answers-the-Wrong-Question">Frequentism Answers the Wrong Question<a class="anchor-link" href="#Frequentism-Answers-the-Wrong-Question">&#182;</a></h2>
</div>

<div class="text_cell_render border-box-sizing rendered_html">
<p>We've shown that the frequentist approach in the second example is <em>technically correct</em>, but it disagrees with our common sense. What are we to take from this?</p>
<p>Here's the crux of the problem: <strong>The frequentist confidence interval, while giving the correct answer, is usually answering the wrong question.</strong> And this wrong-question approach is the result of a probability definition which is <em>fundamental</em> to the frequentist paradigm!</p>
<p>Recall the statements about confidence intervals and credible regions that I made above. From the Bayesians:</p>
<blockquote>
<p>&quot;Given our observed data, there is a 95% probability that the true value of <span class="math">\(\theta\)</span> falls within the credible region&quot; - Bayesians</p>
</blockquote>
<p>And from the frequentists:</p>
<blockquote>
<p>&quot;There is a 95% probability that when I compute a confidence interval from data of this sort, the true value of <span class="math">\(\theta\)</span> will fall within it.&quot; - Frequentists</p>
</blockquote>
<p>Now think about what this means. Suppose you've measured three failure times of your device, and you want to estimate <span class="math">\(\theta\)</span>. I would assert that &quot;data of this sort&quot; is not your primary concern: you should be concerned with what you can learn from <strong>those particular three observations</strong>, not the entire hypothetical space of observations like them. As we saw above, if you follow the frequentists in considering &quot;data of this sort&quot;, you are in danger at arriving at an answer that tells you nothing meaningful about the particular data you have measured.</p>
<p>Suppose you attempt to change the question and ask what the frequentist confidence interval can tell you <em>given the particular data that you've observed</em>. Here's what it has to say:</p>
<blockquote>
<p>&quot;<em>Given this observed data</em>, the true value of <span class="math">\(\theta\)</span> is either in our confidence interval or it isn't&quot; - Frequentists</p>
</blockquote>
<p>That's all the confidence interval means – and all it can mean! – for <strong>this particular data</strong> that you have observed. Really. I'm not making this up. You might notice that this is simply a tautology, and can be put more succinctly:</p>
<blockquote>
<p>&quot;<em>Given this observed data</em>, I can put no constraint on the value of <span class="math">\(\theta\)</span>&quot; - Frequentists</p>
</blockquote>
<p>If you're interested in what your particular, observed data are telling you, frequentism is useless.</p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Hold-on...-isn't-that-a-bit-harsh?">Hold on... isn't that a bit harsh?<a class="anchor-link" href="#Hold-on...-isn't-that-a-bit-harsh?">&#182;</a></h4>
</div>

<div class="text_cell_render border-box-sizing rendered_html">
<p>This might be a harsh conclusion for some to swallow, but I want to emphasize that it is not simply a matter of opinion or idealogy; it's an undeniable fact based on the very philosophical stance underlying frequentism and the very definition of the confidence interval. If what you're interested in are conclusions drawn from the particular data you observed, frequentism's standard answers (i.e. the confidence interval and the closely-related <span class="math">\(p\)</span>-values) are entirely useless.</p>
<p>Unfortunately, most people using frequentist principles in practice don't seem to realize this. I'd point out specific examples from the astronomical literature, but I'm not in the business of embarassing people directly (and they're easy enough to find now that you know what to look for). Many scientists operate as if the confidence interval is a Bayesian credible region, <strong>but it demonstrably is not.</strong> This oversight can perhaps be forgiven for the statistical layperson, as even trained statisticians will often mistake the interpretation of the confidence interval.</p>
<p>I think the reason this mistake is so common is that in many simple cases (as I showed in the first example above) the confidence interval and the credible region happen to coincide. Frequentism, in this case, correctly answers the question you ask, <strong>but only because of the happy accident that Bayesianism gives the same result for that problem.</strong></p>
<p>Now, I should point out that I am certainly not the first person to state things this way, or even this strongly. The Physicist <a href="http://en.wikipedia.org/wiki/Edwin_Thompson_Jaynes">E.T. Jaynes</a> was known as an ardent defender of Bayesianism in science; one of my primary inspirations for this post was his 1976 paper, <em>Confidence Intervals vs. Bayesian Intervals</em> (<a href="http://bayes.wustl.edu/etj/articles/confidence.pdf">pdf</a>). More recently, statistician and blogger <a href="http://wmbriggs.com/">W.M. Briggs</a> posted a diatribe on arXiv called <a href="http://arxiv.org/abs/1201.2590"><em>It's Time To Stop Teaching Frequentism to Non-Statisticians</em></a> which brings up this same point. It's in the same vein of argument that <a href="http://en.wikipedia.org/wiki/Leonard_Jimmie_Savage">Savage</a>, <a href="http://en.wikipedia.org/wiki/Jerome_Cornfield">Cornfield</a>, and other outspoken 20th-century Bayesian practitioners made throughout their writings, talks, and correspondance.</p>
<p>So should you ever use confidence intervals at all? Perhaps in situations (such as analyzing gambling odds) where multiple data realizations are the reality, frequentism makes sense. But in most scientific applications where you're concerned with what one particular observed set of data is telling you, <strong>frequentism simply answers the wrong question</strong>.</p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-Moral-of-the-Story:-Frequentism-and-Science-Do-Not-Mix">The Moral of the Story: Frequentism and Science Do Not Mix<a class="anchor-link" href="#The-Moral-of-the-Story:-Frequentism-and-Science-Do-Not-Mix">&#182;</a></h2>
</div>

<div class="text_cell_render border-box-sizing rendered_html">
<p>The moral of the story is that frequentism and Science do not mix. Let me say it directly: <em>you should be suspicious of the use of frequentist confidence intervals and p-values in science</em>. In a scientific setting, confidence intervals, and closely-related p-values, provide the correct answer to the wrong question. In particular, if you ever find someone stating or implying that a 95% confidence interval is 95% certain to contain a parameter of interest, <strong>do not trust their interpretation or their results</strong>. If you happen to be peer-reviewing the paper, <strong>reject it</strong>. Their data do not back-up their conclusion.</p>
<p>If you have made it this far, I thank you for reading! I hope that this exploration succeeded in clarifying that the philosophical assumptions of frequentism and Bayesianism lead to real, practical consequences in the analysis and interpretation of data. If this post leads just one researcher to stop using frequentist confidence intervals in their scientific research, I will consider it a success.</p>
<p><small> This post was written entirely in the IPython notebook. You can <a href="http://jakevdp.github.io/downloads/notebooks/FreqBayes3.ipynb">download</a> this notebook, or see a static view on <a href="http://nbviewer.ipython.org/url/jakevdp.github.io/downloads/notebooks/FreqBayes3.ipynb">nbviewer</a>. Many thanks to David W. Hogg for some helpful critiques on an early version of this post. </small></p>
</div></p></div>
    <footer>
<p class="meta">
  <span class="byline author vcard">
    Posted by <span class="fn">Jake Vanderplas</span>
  </span>
<time datetime="2014-06-12T12:00:00" pubdate>Jun 12, 2014</time></p><div class="sharing">
  <a href="http://twitter.com/share" class="twitter-share-button" data-url="/blog/2014/06/12/frequentism-and-bayesianism-3-confidence-credibility/" data-via="jakevdp" data-counturl="/blog/2014/06/12/frequentism-and-bayesianism-3-confidence-credibility/" >Tweet</a>
  <div class="g-plusone" data-size="medium"></div>
</div>    </footer>
  </article>

</div>
<aside class="sidebar">
  <section>
    <h1>Recent Posts</h1>
    <ul id="recent_posts">
      <li class="post">
          <a href="/blog/2014/06/14/frequentism-and-bayesianism-4-bayesian-in-python/">Frequentism and Bayesianism IV: How to be a Bayesian in Python</a>
      </li>
      <li class="post">
          <a href="/blog/2014/06/12/frequentism-and-bayesianism-3-confidence-credibility/">Frequentism and Bayesianism III: Confidence, Credibility, and why Frequentism and Science do not Mix</a>
      </li>
      <li class="post">
          <a href="/blog/2014/06/10/is-seattle-really-seeing-an-uptick-in-cycling/">Is Seattle Really Seeing an Uptick In Cycling?</a>
      </li>
      <li class="post">
          <a href="/blog/2014/06/06/frequentism-and-bayesianism-2-when-results-differ/">Frequentism and Bayesianism II: When Results Differ</a>
      </li>
      <li class="post">
          <a href="/blog/2014/05/09/why-python-is-slow/">Why Python is Slow: Looking Under the Hood</a>
      </li>
    </ul>
  </section>
  <section>
      
 

  <section>
  </section>



<section>
    <a href="http://twitter.com/jakevdp" class="twitter-follow-button" data-show-count="true">Follow @jakevdp</a>
</section>
</aside>    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2013 - Jake Vanderplas -
  <span class="credit">Powered by <a href="http://getpelican.com">Pelican</a></span>
</p></footer>
  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>
  <script type="text/javascript">
    (function() {
      var script = document.createElement('script'); script.type = 'text/javascript'; script.async = true;
      script.src = 'https://apis.google.com/js/plusone.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(script, s);
    })();
  </script>
</body>
</html>